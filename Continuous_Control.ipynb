{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "You are welcome to use this coding environment to train your agent for the project.  Follow the instructions below to get started!\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "Run the next code cell to install a few packages.  This line will take a few minutes to run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.5 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The environments corresponding to both versions of the environment are already saved in the Workspace and can be accessed at the file paths provided below.  \n",
    "\n",
    "Please select one of the two options below for loading the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_size -> 5.0\n",
      "\t\tgoal_speed -> 1.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "# select this option to load version 2 (with 20 agents) of the environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [  0.00000000e+00  -4.00000000e+00   0.00000000e+00   1.00000000e+00\n",
      "  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00  -1.00000000e+01   0.00000000e+00\n",
      "   1.00000000e+00  -0.00000000e+00  -0.00000000e+00  -4.37113883e-08\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   5.75471878e+00  -1.00000000e+00\n",
      "   5.55726624e+00   0.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "  -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Note that **in this coding environment, you will not be able to watch the agents while they are training**, and you should set `train_mode=True` to restart the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env_info = env.reset(train_mode=True)[brain_name]      # reset the environment    \n",
    "# states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "# scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "# while True:\n",
    "#     actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "#     actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "#     env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "#     next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "#     rewards = env_info.rewards                         # get reward (for each agent)\n",
    "#     dones = env_info.local_done                        # see if episode finished\n",
    "#     scores += env_info.rewards                         # update the score (for each agent)\n",
    "#     states = next_states                               # roll over states to next time step\n",
    "#     if np.any(dones):                                  # exit loop if episode finished\n",
    "#         break\n",
    "# print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  A few **important notes**:\n",
    "- When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```\n",
    "- To structure your work, you're welcome to work directly in this Jupyter notebook, or you might like to start over with a new file!  You can see the list of files in the workspace by clicking on **_Jupyter_** in the top left corner of the notebook.\n",
    "- In this coding environment, you will not be able to watch the agents while they are training.  However, **_after training the agents_**, you can download the saved model weights to watch the agents on your own machine! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from ddpg_agent import Agent\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "Implementation of DDPG - an algorithm which concurrently learns a Q-function and a policy.\n",
    "\n",
    "Params:\n",
    "    episodes - integer representing maximum number of iterations\n",
    "Return:\n",
    "    scores - list of all averages of all the agents scores for each episode \n",
    "\"\"\"\n",
    "def deep_deterministic_policy_gradient(episodes = 1000):\n",
    "    scores_100 = deque(maxlen = 100)\n",
    "    scores = []\n",
    "    \n",
    "    for episode in range(episodes):\n",
    "        # reset the environment, get current state and \n",
    "        # agents scores (for each of the 20 agents)\n",
    "        environment = env.reset(train_mode = True)[brain_name]\n",
    "        curr_states = environment.vector_observations\n",
    "        curr_agents_scores = np.zeros(num_agents)\n",
    "        mean_score = 0\n",
    "        agent.reset()\n",
    "        \n",
    "        for step in range(2000):\n",
    "            # send all actions and get next states and rewards\n",
    "            curr_actions = agent.act(curr_states)\n",
    "            environment = env.step(curr_actions)[brain_name]\n",
    "            next_states = environment.vector_observations\n",
    "            curr_rewards = environment.rewards\n",
    "            \n",
    "            # check if the episode is finished\n",
    "            is_finished = environment.local_done\n",
    "            \n",
    "            # make a next step, update states and scores\n",
    "            agent.step(curr_states, curr_actions, curr_rewards, next_states, is_finished, step)\n",
    "            curr_states = next_states\n",
    "            curr_agents_scores += curr_rewards\n",
    "            \n",
    "            if np.any(is_finished): break\n",
    "        \n",
    "        # update scores and 100 continuoues scores lists\n",
    "        curr_score = np.mean(curr_agents_scores)\n",
    "        scores.append(np.mean(curr_score))\n",
    "        scores_100.append(np.mean(curr_score))\n",
    "        \n",
    "        print('Episode: {}, Score: {}, Max_Score: {}'.format(episode, curr_score, np.max(scores)))\n",
    "        \n",
    "        if episode != 0 and episode % 10 == 0:\n",
    "            print('Current average:', np.mean(scores_100))\n",
    "            \n",
    "        # check if the environment is solved\n",
    "        if len(scores_100) == 100 and np.mean(scores_100) >= 30:\n",
    "            torch.save(agent.actor_local.state_dict(), 'actor_weights.pth')\n",
    "            torch.save(agent.critic_local.state_dict(), 'critic_weights.pth')\n",
    "            break\n",
    "              \n",
    "    return  scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0, Score: 0.5589999875053764, Max_Score: 0.5589999875053764\n",
      "Episode: 1, Score: 0.27799999378621576, Max_Score: 0.5589999875053764\n",
      "Episode: 2, Score: 0.12099999729543924, Max_Score: 0.5589999875053764\n",
      "Episode: 3, Score: 0.08849999802187085, Max_Score: 0.5589999875053764\n",
      "Episode: 4, Score: 0.03899999912828207, Max_Score: 0.5589999875053764\n",
      "Episode: 5, Score: 0.052999998815357684, Max_Score: 0.5589999875053764\n",
      "Episode: 6, Score: 0.09749999782070518, Max_Score: 0.5589999875053764\n",
      "Episode: 7, Score: 0.04949999889358878, Max_Score: 0.5589999875053764\n",
      "Episode: 8, Score: 0.05049999887123704, Max_Score: 0.5589999875053764\n",
      "Episode: 9, Score: 0.1289999971166253, Max_Score: 0.5589999875053764\n",
      "Episode: 10, Score: 0.0549999987706542, Max_Score: 0.5589999875053764\n",
      "Current average: 0.138181815093\n",
      "Episode: 11, Score: 0.040499999094754456, Max_Score: 0.5589999875053764\n",
      "Episode: 12, Score: 0.11999999731779099, Max_Score: 0.5589999875053764\n",
      "Episode: 13, Score: 0.1599999964237213, Max_Score: 0.5589999875053764\n",
      "Episode: 14, Score: 0.135499996971339, Max_Score: 0.5589999875053764\n",
      "Episode: 15, Score: 0.18849999578669668, Max_Score: 0.5589999875053764\n",
      "Episode: 16, Score: 0.20399999544024466, Max_Score: 0.5589999875053764\n",
      "Episode: 17, Score: 0.48049998925998805, Max_Score: 0.5589999875053764\n",
      "Episode: 18, Score: 0.6404999856837094, Max_Score: 0.6404999856837094\n",
      "Episode: 19, Score: 0.36899999175220727, Max_Score: 0.6404999856837094\n",
      "Episode: 20, Score: 0.6399999856948853, Max_Score: 0.6404999856837094\n",
      "Current average: 0.214214280926\n",
      "Episode: 21, Score: 0.6964999844320119, Max_Score: 0.6964999844320119\n",
      "Episode: 22, Score: 1.2909999711439013, Max_Score: 1.2909999711439013\n",
      "Episode: 23, Score: 1.5239999659359456, Max_Score: 1.5239999659359456\n",
      "Episode: 24, Score: 1.4899999666959047, Max_Score: 1.5239999659359456\n",
      "Episode: 25, Score: 1.5124999661929905, Max_Score: 1.5239999659359456\n",
      "Episode: 26, Score: 1.7319999612867831, Max_Score: 1.7319999612867831\n",
      "Episode: 27, Score: 1.696999962069094, Max_Score: 1.7319999612867831\n",
      "Episode: 28, Score: 1.8364999589510262, Max_Score: 1.8364999589510262\n",
      "Episode: 29, Score: 1.8749999580904841, Max_Score: 1.8749999580904841\n",
      "Episode: 30, Score: 2.005999955162406, Max_Score: 2.005999955162406\n",
      "Current average: 0.650290308046\n",
      "Episode: 31, Score: 2.223999950289726, Max_Score: 2.223999950289726\n",
      "Episode: 32, Score: 2.3759999468922617, Max_Score: 2.3759999468922617\n",
      "Episode: 33, Score: 2.8904999353922904, Max_Score: 2.8904999353922904\n",
      "Episode: 34, Score: 3.3399999253451824, Max_Score: 3.3399999253451824\n",
      "Episode: 35, Score: 3.02849993230775, Max_Score: 3.3399999253451824\n",
      "Episode: 36, Score: 3.3829999243840576, Max_Score: 3.3829999243840576\n",
      "Episode: 37, Score: 3.9414999119006096, Max_Score: 3.9414999119006096\n",
      "Episode: 38, Score: 4.556999898143113, Max_Score: 4.556999898143113\n",
      "Episode: 39, Score: 4.44049990074709, Max_Score: 4.556999898143113\n",
      "Episode: 40, Score: 4.4989998994395135, Max_Score: 4.556999898143113\n",
      "Current average: 1.33753655547\n",
      "Episode: 41, Score: 4.2054999059997495, Max_Score: 4.556999898143113\n",
      "Episode: 42, Score: 5.306999881379307, Max_Score: 5.306999881379307\n",
      "Episode: 43, Score: 4.841999891772867, Max_Score: 5.306999881379307\n",
      "Episode: 44, Score: 5.5159998767077925, Max_Score: 5.5159998767077925\n",
      "Episode: 45, Score: 5.303999881446361, Max_Score: 5.5159998767077925\n",
      "Episode: 46, Score: 5.876499868649989, Max_Score: 5.876499868649989\n",
      "Episode: 47, Score: 7.103999841213226, Max_Score: 7.103999841213226\n",
      "Episode: 48, Score: 6.049999864771962, Max_Score: 7.103999841213226\n",
      "Episode: 49, Score: 7.031499842833727, Max_Score: 7.103999841213226\n",
      "Episode: 50, Score: 7.7604998265393075, Max_Score: 7.7604998265393075\n",
      "Current average: 2.23207838148\n",
      "Episode: 51, Score: 8.796999803371728, Max_Score: 8.796999803371728\n",
      "Episode: 52, Score: 7.162499839905649, Max_Score: 8.796999803371728\n",
      "Episode: 53, Score: 7.486499832663685, Max_Score: 8.796999803371728\n",
      "Episode: 54, Score: 9.073999797180296, Max_Score: 9.073999797180296\n",
      "Episode: 55, Score: 8.27049981513992, Max_Score: 9.073999797180296\n",
      "Episode: 56, Score: 8.619999807327986, Max_Score: 9.073999797180296\n",
      "Episode: 57, Score: 8.936999800242484, Max_Score: 9.073999797180296\n",
      "Episode: 58, Score: 9.2439997933805, Max_Score: 9.2439997933805\n",
      "Episode: 59, Score: 9.330999791435897, Max_Score: 9.330999791435897\n",
      "Episode: 60, Score: 9.613999785110355, Max_Score: 9.613999785110355\n",
      "Current average: 3.28479500855\n",
      "Episode: 61, Score: 9.063999797403813, Max_Score: 9.613999785110355\n",
      "Episode: 62, Score: 9.667499783914536, Max_Score: 9.667499783914536\n",
      "Episode: 63, Score: 9.934999777935445, Max_Score: 9.934999777935445\n",
      "Episode: 64, Score: 10.306999769620598, Max_Score: 10.306999769620598\n",
      "Episode: 65, Score: 10.203999771922827, Max_Score: 10.306999769620598\n",
      "Episode: 66, Score: 10.825499758031219, Max_Score: 10.825499758031219\n",
      "Episode: 67, Score: 10.699499760847539, Max_Score: 10.825499758031219\n",
      "Episode: 68, Score: 11.071999752521515, Max_Score: 11.071999752521515\n",
      "Episode: 69, Score: 10.862499757204205, Max_Score: 11.071999752521515\n",
      "Episode: 70, Score: 12.215499726962298, Max_Score: 12.215499726962298\n",
      "Current average: 4.29894356588\n",
      "Episode: 71, Score: 12.510999720357358, Max_Score: 12.510999720357358\n",
      "Episode: 72, Score: 11.885999734327196, Max_Score: 12.510999720357358\n",
      "Episode: 73, Score: 11.913499733712523, Max_Score: 12.510999720357358\n",
      "Episode: 74, Score: 12.959999710321426, Max_Score: 12.959999710321426\n",
      "Episode: 75, Score: 12.928499711025506, Max_Score: 12.959999710321426\n",
      "Episode: 76, Score: 13.338499701861291, Max_Score: 13.338499701861291\n",
      "Episode: 77, Score: 13.780499691981822, Max_Score: 13.780499691981822\n",
      "Episode: 78, Score: 13.937999688461423, Max_Score: 13.937999688461423\n",
      "Episode: 79, Score: 14.517499675508589, Max_Score: 14.517499675508589\n",
      "Episode: 80, Score: 13.733499693032353, Max_Score: 14.517499675508589\n",
      "Current average: 5.3917529659\n",
      "Episode: 81, Score: 16.737499625887722, Max_Score: 16.737499625887722\n",
      "Episode: 82, Score: 15.934999643824995, Max_Score: 16.737499625887722\n",
      "Episode: 83, Score: 16.950999621115624, Max_Score: 16.950999621115624\n",
      "Episode: 84, Score: 17.14899961668998, Max_Score: 17.14899961668998\n",
      "Episode: 85, Score: 19.599499561917035, Max_Score: 19.599499561917035\n",
      "Episode: 86, Score: 19.617499561514705, Max_Score: 19.617499561514705\n",
      "Episode: 87, Score: 21.996999508328734, Max_Score: 21.996999508328734\n",
      "Episode: 88, Score: 20.89099953304976, Max_Score: 21.996999508328734\n",
      "Episode: 89, Score: 21.155499527137728, Max_Score: 21.996999508328734\n",
      "Episode: 90, Score: 24.709499447699635, Max_Score: 24.709499447699635\n",
      "Current average: 6.93928006468\n",
      "Episode: 91, Score: 24.327999456226827, Max_Score: 24.709499447699635\n",
      "Episode: 92, Score: 25.090499439183624, Max_Score: 25.090499439183624\n",
      "Episode: 93, Score: 25.652499426621944, Max_Score: 25.652499426621944\n",
      "Episode: 94, Score: 26.29149941233918, Max_Score: 26.29149941233918\n",
      "Episode: 95, Score: 27.554999384097755, Max_Score: 27.554999384097755\n",
      "Episode: 96, Score: 26.55399940647185, Max_Score: 27.554999384097755\n",
      "Episode: 97, Score: 26.66199940405786, Max_Score: 27.554999384097755\n",
      "Episode: 98, Score: 27.316999389417468, Max_Score: 27.554999384097755\n",
      "Episode: 99, Score: 29.074999350123107, Max_Score: 29.074999350123107\n",
      "Episode: 100, Score: 27.59549938319251, Max_Score: 29.074999350123107\n",
      "Current average: 8.9703647995\n",
      "Episode: 101, Score: 27.47549938587472, Max_Score: 29.074999350123107\n",
      "Episode: 102, Score: 29.016999351419507, Max_Score: 29.074999350123107\n",
      "Episode: 103, Score: 26.906999398581682, Max_Score: 29.074999350123107\n",
      "Episode: 104, Score: 27.618999382667244, Max_Score: 29.074999350123107\n",
      "Episode: 105, Score: 28.533499362226575, Max_Score: 29.074999350123107\n",
      "Episode: 106, Score: 28.9919993519783, Max_Score: 29.074999350123107\n",
      "Episode: 107, Score: 28.31249936716631, Max_Score: 29.074999350123107\n",
      "Episode: 108, Score: 29.548499339539557, Max_Score: 29.548499339539557\n",
      "Episode: 109, Score: 28.939999353140593, Max_Score: 29.548499339539557\n",
      "Episode: 110, Score: 29.53549933983013, Max_Score: 29.548499339539557\n",
      "Current average: 11.809559736\n",
      "Episode: 111, Score: 28.968499352503567, Max_Score: 29.548499339539557\n",
      "Episode: 112, Score: 30.91799930892885, Max_Score: 30.91799930892885\n",
      "Episode: 113, Score: 30.304999322630465, Max_Score: 30.91799930892885\n",
      "Episode: 114, Score: 31.381499298568816, Max_Score: 31.381499298568816\n",
      "Episode: 115, Score: 32.80749926669523, Max_Score: 32.80749926669523\n",
      "Episode: 116, Score: 33.07499926071614, Max_Score: 33.07499926071614\n",
      "Episode: 117, Score: 33.83199924379587, Max_Score: 33.83199924379587\n",
      "Episode: 118, Score: 33.734499245975165, Max_Score: 33.83199924379587\n",
      "Episode: 119, Score: 33.06399926096201, Max_Score: 33.83199924379587\n",
      "Episode: 120, Score: 32.75699926782399, Max_Score: 33.83199924379587\n",
      "Current average: 14.988204665\n",
      "Episode: 121, Score: 33.836499243695286, Max_Score: 33.836499243695286\n",
      "Episode: 122, Score: 35.0924992156215, Max_Score: 35.0924992156215\n",
      "Episode: 123, Score: 33.67049924740568, Max_Score: 35.0924992156215\n",
      "Episode: 124, Score: 33.9589992409572, Max_Score: 35.0924992156215\n",
      "Episode: 125, Score: 34.77149922279641, Max_Score: 35.0924992156215\n",
      "Episode: 126, Score: 35.87149919820949, Max_Score: 35.87149919820949\n",
      "Episode: 127, Score: 35.92849919693545, Max_Score: 35.92849919693545\n",
      "Episode: 128, Score: 34.957499218638986, Max_Score: 35.92849919693545\n",
      "Episode: 129, Score: 35.374999209307134, Max_Score: 35.92849919693545\n",
      "Episode: 130, Score: 35.75749920075759, Max_Score: 35.92849919693545\n",
      "Current average: 18.3237995904\n",
      "Episode: 131, Score: 35.339999210089445, Max_Score: 35.92849919693545\n",
      "Episode: 132, Score: 36.960999173857275, Max_Score: 36.960999173857275\n",
      "Episode: 133, Score: 36.40849918620661, Max_Score: 36.960999173857275\n",
      "Episode: 134, Score: 36.67099918033928, Max_Score: 36.960999173857275\n",
      "Episode: 135, Score: 35.73199920132756, Max_Score: 36.960999173857275\n",
      "Episode: 136, Score: 35.73599920123816, Max_Score: 36.960999173857275\n",
      "Episode: 137, Score: 36.407999186217786, Max_Score: 36.960999173857275\n",
      "Episode: 138, Score: 34.69349922453985, Max_Score: 36.960999173857275\n",
      "Episode: 139, Score: 36.85199917629361, Max_Score: 36.960999173857275\n",
      "Episode: 140, Score: 34.58849922688678, Max_Score: 36.960999173857275\n",
      "Current average: 21.5709045179\n",
      "Episode: 141, Score: 34.351999232172965, Max_Score: 36.960999173857275\n",
      "Episode: 142, Score: 36.93599917441607, Max_Score: 36.960999173857275\n",
      "Episode: 143, Score: 34.775499222707005, Max_Score: 36.960999173857275\n",
      "Episode: 144, Score: 37.586499159876254, Max_Score: 37.586499159876254\n",
      "Episode: 145, Score: 36.33449918786064, Max_Score: 37.586499159876254\n",
      "Episode: 146, Score: 36.44099918548018, Max_Score: 37.586499159876254\n",
      "Episode: 147, Score: 36.55399918295443, Max_Score: 37.586499159876254\n",
      "Episode: 148, Score: 36.08749919338152, Max_Score: 37.586499159876254\n",
      "Episode: 149, Score: 36.888499175477776, Max_Score: 37.586499159876254\n",
      "Episode: 150, Score: 37.236499167699364, Max_Score: 37.586499159876254\n",
      "Current average: 24.6128544499\n",
      "Episode: 151, Score: 35.80549919968471, Max_Score: 37.586499159876254\n",
      "Episode: 152, Score: 36.84799917638302, Max_Score: 37.586499159876254\n",
      "Episode: 153, Score: 36.64349918095395, Max_Score: 37.586499159876254\n",
      "Episode: 154, Score: 35.52949920585379, Max_Score: 37.586499159876254\n",
      "Episode: 155, Score: 37.334499165508895, Max_Score: 37.586499159876254\n",
      "Episode: 156, Score: 37.49149916199967, Max_Score: 37.586499159876254\n",
      "Episode: 157, Score: 37.193499168660495, Max_Score: 37.586499159876254\n",
      "Episode: 158, Score: 36.890999175421896, Max_Score: 37.586499159876254\n",
      "Episode: 159, Score: 37.02149917250499, Max_Score: 37.586499159876254\n",
      "Episode: 160, Score: 36.56349918274209, Max_Score: 37.586499159876254\n",
      "Current average: 27.4207093871\n",
      "Episode: 161, Score: 37.14549916973338, Max_Score: 37.586499159876254\n",
      "Episode: 162, Score: 36.52999918349087, Max_Score: 37.586499159876254\n",
      "Episode: 163, Score: 37.39699916411191, Max_Score: 37.586499159876254\n",
      "Episode: 164, Score: 34.567499227356166, Max_Score: 37.586499159876254\n",
      "Episode: 165, Score: 36.82099917698652, Max_Score: 37.586499159876254\n",
      "Episode: 166, Score: 36.75099917855114, Max_Score: 37.586499159876254\n",
      "Episode: 167, Score: 36.556999182887374, Max_Score: 37.586499159876254\n",
      "Episode: 168, Score: 35.295999211072925, Max_Score: 37.586499159876254\n",
      "Episode: 169, Score: 34.718499223981055, Max_Score: 37.586499159876254\n",
      "Episode: 170, Score: 33.07849926063791, Max_Score: 37.586499159876254\n",
      "Current average: 29.9608043303\n",
      "Episode: 171, Score: 32.433499275054785, Max_Score: 37.586499159876254\n"
     ]
    }
   ],
   "source": [
    "agent = Agent(state_size = state_size, action_size = action_size, random_seed = 8)\n",
    "scores = deep_deterministic_policy_gradient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ffb58d0f0f0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot the 100 consecutive scores average\n",
    "plt.plot(scores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('fc1.weight',\n",
       "              tensor([[-5.6920e-01,  4.9079e-01,  5.4036e-02,  ..., -9.8431e-01,\n",
       "                       -6.0770e-02, -1.6672e+00],\n",
       "                      [ 2.7951e-01, -6.7725e-01, -2.5012e-01,  ..., -5.3218e-01,\n",
       "                        4.0439e-02,  2.1862e+00],\n",
       "                      [-3.7487e-01,  1.0480e-01,  5.0113e-01,  ..., -2.6950e-01,\n",
       "                        2.3063e-02,  1.9591e+00],\n",
       "                      ...,\n",
       "                      [-1.4759e-01, -5.0917e-01,  2.5387e-01,  ..., -4.1037e-01,\n",
       "                        5.5372e-02, -1.4304e+00],\n",
       "                      [ 1.3944e-01,  5.6462e-01, -3.4015e-01,  ..., -9.9595e-01,\n",
       "                        5.6458e-02, -9.3357e-01],\n",
       "                      [-2.4218e-01,  9.2092e-01, -1.4550e-03,  ..., -8.5305e-01,\n",
       "                        1.7348e-02,  2.0568e+00]], device='cuda:0')),\n",
       "             ('fc1.bias',\n",
       "              tensor([-0.8780, -0.6347, -0.4072, -0.4306, -0.0360, -0.1937, -0.2483,\n",
       "                      -0.4026, -0.9695, -0.5470, -1.0217, -0.2116, -0.5566, -0.4480,\n",
       "                      -0.6704,  0.0420, -0.9672, -0.8519,  0.0162, -0.4331, -1.0689,\n",
       "                      -0.9969, -0.1786, -0.4867, -0.0374, -0.7278, -0.1235, -0.7662,\n",
       "                      -0.0871, -0.5577, -0.7177, -0.8978, -0.0116, -0.3615, -0.1693,\n",
       "                      -0.2118, -0.5880, -0.6689, -0.9070, -0.4624, -0.7815, -0.9103,\n",
       "                      -0.7183, -0.5070, -0.2958, -0.6239, -0.4885, -1.1190, -0.7704,\n",
       "                      -0.6886, -0.5966, -0.7176, -0.8204, -0.7907, -0.3098, -0.4268,\n",
       "                      -0.3448, -0.2894, -0.7499, -0.4877, -0.4442, -0.5070, -0.4585,\n",
       "                      -0.4958, -0.7314, -1.1019, -0.4349, -0.1242, -0.2599, -1.0474,\n",
       "                      -0.3951, -0.9027, -0.3458, -0.0467, -0.7380, -0.3815, -0.5050,\n",
       "                      -0.1960, -0.7861, -0.2117, -0.2521, -0.5338, -0.5043, -0.1455,\n",
       "                      -1.0506,  0.0279,  0.2610, -0.2629, -0.1636, -1.0519, -1.3036,\n",
       "                      -0.8933, -0.4002, -0.2295, -1.2444, -1.2286,  0.2270, -0.3620,\n",
       "                      -1.1239, -0.6843, -0.1940, -0.3817, -1.1665, -1.2541, -0.9395,\n",
       "                      -0.9985, -0.6266, -0.9888, -0.3810, -0.5751, -1.1974, -0.0234,\n",
       "                      -0.3228, -0.6623, -0.2719, -0.8499, -0.1708, -0.3559, -0.6600,\n",
       "                      -0.5661, -0.6093, -0.6231, -0.8231, -0.7003, -0.7469, -0.8580,\n",
       "                      -0.5110, -0.7711, -0.7923, -0.5878, -0.8447, -0.0048, -0.9650,\n",
       "                      -0.2757, -0.3198, -0.4422, -0.1301, -0.2465,  0.0252, -0.5304,\n",
       "                      -0.2376, -0.5182, -0.3584, -1.1117, -0.4424, -0.4661, -0.7072,\n",
       "                       0.4294, -0.2536,  0.1788, -1.1026, -0.5004, -0.7366, -0.8012,\n",
       "                      -0.0992, -0.9167, -0.3899, -0.3828, -0.8726, -0.8718, -0.3736,\n",
       "                      -0.2264, -0.4258, -0.9896, -0.0150,  0.0133, -0.4776, -0.8730,\n",
       "                      -0.5061, -0.2552, -0.9716, -0.7600, -0.1571,  0.0270, -0.6168,\n",
       "                      -0.8283, -0.2683, -0.9099, -0.7300, -0.6503, -0.7141, -0.7372,\n",
       "                      -0.7265, -0.0965, -0.5948, -0.8964, -0.2565, -0.3565,  0.0486,\n",
       "                      -0.2457, -0.6082, -0.2491, -0.2469, -0.9695, -0.7018, -1.1647,\n",
       "                      -0.4320, -1.2296, -0.2732, -0.8576, -0.7054, -0.5598, -0.4924,\n",
       "                      -0.6860, -0.4849, -0.5894, -0.6614, -0.0152, -0.2922, -0.7022,\n",
       "                      -0.7070, -0.9192,  0.1890, -1.3848, -0.1172, -0.9933, -1.1082,\n",
       "                      -0.8445, -0.8370, -0.2877,  0.0231, -0.5156, -0.5833, -0.4842,\n",
       "                      -0.7774, -1.2119, -0.8386, -0.9680, -0.6602, -0.7263, -0.0827,\n",
       "                      -0.3974, -0.1975, -0.5205, -0.3567,  0.0511, -0.3102, -0.6284,\n",
       "                      -0.8267, -0.7780, -0.8947, -0.0123, -0.6176, -0.8360, -0.3729,\n",
       "                      -0.5320, -0.6871, -0.2982, -0.0950, -0.4846, -0.9801, -0.3862,\n",
       "                      -0.7988, -0.2220, -0.9574, -0.8935], device='cuda:0')),\n",
       "             ('fc2.weight',\n",
       "              tensor([[-0.1728, -0.6119, -0.9047,  ..., -0.2006,  0.4874,  0.6743],\n",
       "                      [-1.1568,  0.0129, -0.1526,  ...,  1.4219, -0.6111,  0.8319],\n",
       "                      [-0.1696, -0.3157,  0.2525,  ...,  0.8567,  0.0997, -1.6409],\n",
       "                      [ 1.1774,  1.1895,  0.5074,  ..., -1.2255, -0.8505, -1.4549]], device='cuda:0')),\n",
       "             ('fc2.bias',\n",
       "              tensor([ 0.1566, -0.2848, -0.0714, -0.0623], device='cuda:0'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test loading the weights\n",
    "torch.load('actor_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
